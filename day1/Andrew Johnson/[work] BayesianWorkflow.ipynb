{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrjohns/ProbAI-2024/blob/main/BayesianWorkflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bayesian Workflow - Probabilistic AI School 2024\n",
        "\n",
        "## Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Use a repository of pre-built package binaries to speed-up installation\n",
        "download.file(\"https://github.com/eddelbuettel/r2u/raw/master/inst/scripts/add_cranapt_jammy.sh\",\n",
        "              \"add_cranapt_jammy.sh\")\n",
        "Sys.chmod(\"add_cranapt_jammy.sh\", \"0755\")\n",
        "system(\"./add_cranapt_jammy.sh\")\n",
        "\n",
        "# Install the R Packages we'll be using\n",
        "install.packages(c(\"dplyr\", \"bayesplot\", \"cmdstanr\"),\n",
        "                  repos = c(\"https://stan-dev.r-universe.dev\", getOption(\"repos\")))\n",
        "\n",
        "# Install and setup CmdStan\n",
        "download.file(\"https://github.com/stan-dev/cmdstan/releases/download/v2.35.0/colab-cmdstan-2.35.0.tgz\",\n",
        "              \"cmdstan-2.35.0.tgz\")\n",
        "utils::untar(\"cmdstan-2.35.0.tgz\")\n",
        "cmdstanr::set_cmdstan_path(\"cmdstan-2.35.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial we will be using the [cmdstanr](https://mc-stan.org/cmdstanr/articles/cmdstanr.html) R interface to CmdStan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Download the files for the tutorial\n",
        "system(\"git clone https://github.com/andrjohns/ProbAI-2024\")\n",
        "setwd(\"ProbAI-2024\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition to cmdstanr, we'll be using the [bayesplot](https://mc-stan.org/bayesplot/articles/graphical-ppcs.html) package for our graphical model checking, so let's load that library as well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "library(cmdstanr)\n",
        "library(bayesplot)\n",
        "library(ggplot2)\n",
        "library(dplyr)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Epilepsy RCT Workflow\n",
        "### Data\n",
        "Let's load our dataset and look at the general structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "epilepsy_rct <- readRDS(\"epilepsy.rds\")\n",
        "head(epilepsy_rct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Model\n",
        "\n",
        "We've decided to use a normal linear regression as our initial attempt for modelling the data:\n",
        "\n",
        "$$\n",
        "y_i \\sim \\textbf{N}(\\alpha + x_i^T\\beta, \\sigma) \\\\\n",
        "\\alpha \\sim N(0,10) \\\\\n",
        "\\beta \\sim N(0,5) \\\\\n",
        "\\sigma \\sim \\textbf{N}^+(0,5)\n",
        "$$\n",
        "\n",
        "Let's have a look at how we would specify this in Stan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/normal_glm.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our model, and we've defined the data we'll need, let's structure our epilepsy observations to the right format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "epilepsy_prep <- epilepsy_rct |>\n",
        "  mutate(Trt = as.numeric(Trt) - 1,\n",
        "         visit = as.numeric(visit) - 1,\n",
        "         treat_x_visit = Trt * visit)\n",
        "\n",
        "epilepsy_stan <- list(\n",
        "  N = length(unique(epilepsy_prep$patient)),\n",
        "  T = length(unique(epilepsy_prep$visit)),\n",
        "  K = 5,\n",
        "  x = epilepsy_prep[,c(\"Trt\", \"visit\", \"treat_x_visit\", \"zAge\", \"zBase\")],\n",
        "  y = epilepsy_prep$count,\n",
        "  sample_prior = 1\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we're ready to fit our model! Remember that Stan is a *compiled* language, so first we need to compile our Stan model into an executable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod <- cmdstan_model(\"Stan/normal_glm.stan\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that it's compiled, we can begin the simulation process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1mmqLsb4HGh",
        "outputId": "d0075e89-7d3b-4542-bc08-5eb58c500e62",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit <- mod$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2024\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To perform our prior-predictive checks, we can use the `ppd_dens_overlay` function from the `bayesplot` package to plot the densities of the simulated data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppd_dens_overlay(fit$draws(variables = \"ypred\", format = \"draws_matrix\")[1:25, ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2: Poisson GLM\n",
        "\n",
        "We've decided to use a Poisson Generalised Linear Model with a log-link as our second attempt for modelling the data:\n",
        "\n",
        "$$\n",
        "y_i \\sim Poisson(\\lambda_i) \\\\\n",
        "\\lambda_i = \\exp(\\alpha + x_i^T\\beta) \\\\\n",
        "\\alpha \\sim N(0,5) \\\\\n",
        "\\beta_{1:4} \\sim N(0,1)\n",
        "$$\n",
        "\n",
        "Let's have a look at how we would specify this in Stan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/poisson.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And let's check our new prior-predictive results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod <- cmdstan_model(\"Stan/poisson.stan\")\n",
        "fit <- mod$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2024\n",
        ")\n",
        "ppd_dens_overlay(fit$draws(variables = \"ypred\", format = \"draws_matrix\")[1:25, ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Much better! Let's fit the model to the observed data now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "epilepsy_stan$sample_prior <- 0\n",
        "fit <- mod$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2024\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check our diagnostics to see how the sampling went. First up, do the traceplots indicate that the chains have converged?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mcmc_trace(fit$draws(\"beta\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking good! Let's also check our R-hat statistic and effective sample sizes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit$summary(\"beta\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not bad! Let's have a look at our posterior-predictive checks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$y,\n",
        "                 fit$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like there are some areas where our model doesn't represent our data very well, let's see what we can do about that."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random-Effects Model\n",
        "\n",
        "We'll add a random intercept for each individual, to relax the assumption of equal mean and variance in the Poisson:\n",
        "\n",
        "$$\n",
        "y_i \\sim Poisson(\\lambda_i\\theta_i) \\\\\n",
        "\\lambda_i = \\exp(\\alpha + x_i^T\\beta) \\\\\n",
        "\\alpha \\sim N(0,5) \\\\\n",
        "\\beta_{1:4} \\sim N(0,1) \\\\\n",
        "\\theta_i \\sim Gamma(\\phi,\\phi) \\\\\n",
        "\\phi \\sim Cauchy^+(0,5)\n",
        "$$\n",
        "\n",
        "How does this look in our Stan model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/poisson_gamma.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also need to add an indicator for each individual in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "epilepsy_stan$ID <- as.numeric(epilepsy_prep$patient)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's follow the same process of compiling our model and then running sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod_ranef <- cmdstan_model(\"Stan/poisson_gamma.stan\")\n",
        "fit_ranef <- mod_ranef$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How do our convergence diagnostics and effective sample sizes look?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mcmc_trace(fit_ranef$draws(\"beta\"))\n",
        "fit_ranef$summary(\"beta\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How about our fit to the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$y,\n",
        "                 fit_ranef$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Much better! Now that we have a possible model, let's look at making it a little more efficient"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Marginalisation\n",
        "\n",
        "Remember that we can represent the Poisson with a Gamma-distributed random effect as a Negative-Binomial parameterised by its mean and dispersion:\n",
        "\n",
        "$$\n",
        "\\int Poisson(y | \\lambda\\theta) \\cdot Gamma(\\theta | \\phi, \\phi) d\\theta = NB(y|\\lambda, \\phi)\n",
        "$$\n",
        "\n",
        "But don't just take my word for it, let's verify this in R by comparing the numerically integrated Poisson-Gamma with the Negative-Binomial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "lambda <- 2.65\n",
        "y <- 4\n",
        "phi <- 1.5\n",
        "\n",
        "poisson_gamma_pdf <- function(theta, y, lambda, phi) {\n",
        "  exp(dpois(y, lambda * theta, log = TRUE) + dgamma(theta, shape = phi, rate = phi, log = TRUE))\n",
        "}\n",
        "\n",
        "integrate(poisson_gamma_pdf, 0, Inf, y, lambda, phi)\n",
        "dnbinom(y, mu = lambda, size = phi)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Brilliant! Let's put this into practice with Stan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/nb.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod_nb <- cmdstan_model(\"Stan/nb.stan\")\n",
        "fit_nb <- mod_nb$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$y,\n",
        "                 fit_nb$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking good again! How are our sampling runtimes looking?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit_ranef$time()$total\n",
        "fit_nb$time()$total"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Well that's a pretty impressive improvement! How much better can we do if we use the optimised GLM distributions in Stan?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cat(readLines(\"Stan/nb_glm.stan\"), sep = \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mod_nb_glm <- cmdstan_model(\"Stan/nb_glm.stan\")\n",
        "fit_nb_glm <- mod_nb_glm$sample(\n",
        "  data = epilepsy_stan,\n",
        "  parallel_chains = 4,\n",
        "  refresh = 0,\n",
        "  show_messages = FALSE,\n",
        "  show_exceptions = FALSE,\n",
        "  seed = 2023\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ppc_dens_overlay(y = epilepsy_stan$y,\n",
        "                 fit_nb_glm$draws(\"ypred\", format = \"draws_matrix\")[1:20,]) +\n",
        "  coord_cartesian(xlim=c(0,100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit_ranef$time()$total\n",
        "fit_nb$time()$total\n",
        "fit_nb_glm$time()$total"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that's a nice (and scalable) improvement!\n",
        "\n",
        "### Compare Models\n",
        "\n",
        "Now that we've finished developing our models (for now), how do they differ? Why would we prefer one over the other? Let's look at our inferences for the treatment effect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "fit_ranef$summary(\"beta[1]\")\n",
        "fit_nb_glm$summary(\"beta[1]\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The more efficient sampling of the NG-GLM model resulted in less (computational) uncertainty in our estimates, a narrower posterior and greater effective sample size.\n",
        "\n",
        "We can also see this by plotting the treatment effect posterior for each model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "mcmc_dens(fit_ranef$draws(\"beta[1]\")) + coord_cartesian(xlim=c(-1,0.5))\n",
        "mcmc_dens(fit_nb_glm$draws(\"beta[1]\")) + coord_cartesian(xlim=c(-1,0.5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNugLpRwFRzPFRoR7Z9SLZO",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
